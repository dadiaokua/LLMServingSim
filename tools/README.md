# LLMServingSim å·¥å…·ç›®å½•

è¿™ä¸ªç›®å½•åŒ…å«äº†LLMServingSimçš„å„ç§å·¥å…·å’Œè„šæœ¬ï¼ŒæŒ‰åŠŸèƒ½åˆ†ç±»ç»„ç»‡ã€‚

## ğŸ“ ç›®å½•ç»“æ„

```
tools/
â”œâ”€â”€ scripts/           # å¯åŠ¨å’Œè¿è¡Œè„šæœ¬
â”œâ”€â”€ perf_models/       # æ€§èƒ½æ¨¡å‹ç”Ÿæˆå·¥å…·
â”œâ”€â”€ tests/            # æµ‹è¯•å·¥å…·
â””â”€â”€ README.md         # æœ¬æ–‡æ¡£
```

## ğŸš€ scripts/ - å¯åŠ¨è„šæœ¬

### `run_openai_server.sh`
å¯åŠ¨OpenAIå…¼å®¹çš„APIæœåŠ¡å™¨

```bash
# ä½¿ç”¨æ–¹æ³•
tools/scripts/run_openai_server.sh [é€‰é¡¹]

# é€‰é¡¹
--port PORT         HTTPæœåŠ¡å™¨ç«¯å£ (é»˜è®¤: 8000)
--host HOST         HTTPæœåŠ¡å™¨ä¸»æœº (é»˜è®¤: localhost)  
--model MODEL       æ¨¡å‹åç§°
--npu_num NUM       NPUæ•°é‡ (é»˜è®¤: 1)

# ç¤ºä¾‹
tools/scripts/run_openai_server.sh --port 8080 --model "qwen/Qwen3-8B" --hardware A100
```

### `run_idle.sh`
å¯åŠ¨ç©ºé—²æ¨¡å¼æœåŠ¡å™¨ï¼ˆåªç›‘å¬ï¼Œä¸ç”Ÿæˆæµé‡ï¼‰

```bash
tools/scripts/run_idle.sh
```

### `demo_curl_response.sh`
æ˜¾ç¤ºcurlä½¿ç”¨ç¤ºä¾‹å’Œé¢„æœŸå“åº”æ ¼å¼

```bash
tools/scripts/demo_curl_response.sh
```

## ğŸ”§ perf_models/ - æ€§èƒ½æ¨¡å‹å·¥å…·

### `generate_perf_models.py`
ä¸ºå¤šç§ç¡¬ä»¶ç”Ÿæˆæ€§èƒ½æ¨¡å‹æ–‡ä»¶

```bash
# ç”Ÿæˆæ‰€æœ‰ç¡¬ä»¶çš„æ€§èƒ½æ¨¡å‹
python3 tools/perf_models/generate_perf_models.py

# ç”Ÿæˆçš„ç¡¬ä»¶ç±»å‹
- H100 (3.5x faster than RTX3090)
- A100 (2.2x faster)
- L40, RTX4090, A6000, A40, RTX4080, RTX3090, A10, V100, T4
```

### `extend_perf_models.py`
ä¸ºç°æœ‰ç¡¬ä»¶æ·»åŠ æ–°æ¨¡å‹æ”¯æŒ

```bash
# ä¸ºæ‰€æœ‰ç¡¬ä»¶æ·»åŠ æ–°æ¨¡å‹æ”¯æŒ
python3 tools/perf_models/extend_perf_models.py

# æ”¯æŒçš„æ¨¡å‹
- qwen/Qwen3-8B
- meta-llama/Llama-3.1-8B-Instruct  
- facebook/opt-6.7b
```

## ğŸ§ª tests/ - æµ‹è¯•å·¥å…·

### `test_openai_api.py`
æµ‹è¯•OpenAIå…¼å®¹APIçš„æ‰€æœ‰ç«¯ç‚¹

```bash
# æµ‹è¯•é»˜è®¤æœåŠ¡å™¨ (localhost:8000)
python3 tools/tests/test_openai_api.py

# æµ‹è¯•æŒ‡å®šæœåŠ¡å™¨
python3 tools/tests/test_openai_api.py http://localhost:8080

# æµ‹è¯•å†…å®¹
- /v1/models ç«¯ç‚¹
- /v1/chat/completions ç«¯ç‚¹
- /v1/completions ç«¯ç‚¹
- OpenAI Pythonå®¢æˆ·ç«¯å…¼å®¹æ€§
```

### `test_http_api.py`
æµ‹è¯•åŸºç¡€HTTPæ¥å£

```bash
python3 tools/tests/test_http_api.py [æœåŠ¡å™¨åœ°å€]

# æµ‹è¯•å†…å®¹
- å¥åº·æ£€æŸ¥
- æœåŠ¡çŠ¶æ€
- åŸºç¡€ç”Ÿæˆæ¥å£
```

## ğŸ¯ ä½¿ç”¨ç»Ÿä¸€å¯åŠ¨å™¨

æ¨èä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•çš„ `llmservingsim` è„šæœ¬ä½œä¸ºç»Ÿä¸€å…¥å£ï¼š

```bash
# å¯åŠ¨æœåŠ¡å™¨
./llmservingsim server --model "qwen/Qwen3-8B" --hardware A100

# ç”Ÿæˆæ€§èƒ½æ¨¡å‹
./llmservingsim setup-perf

# æµ‹è¯•API
./llmservingsim test-api

# æŸ¥çœ‹å¸®åŠ©
./llmservingsim help
```

## ğŸ“Š å·¥å…·ä¾èµ–å…³ç³»

```
generate_perf_models.py  â†’  åˆ›å»ºåŸºç¡€æ€§èƒ½æ¨¡å‹
         â†“
extend_perf_models.py    â†’  æ·»åŠ æ›´å¤šæ¨¡å‹æ”¯æŒ
         â†“
run_openai_server.sh     â†’  å¯åŠ¨æœåŠ¡å™¨
         â†“
test_openai_api.py       â†’  æµ‹è¯•æœåŠ¡å™¨åŠŸèƒ½
```

## ğŸ”„ å·¥ä½œæµç¨‹

1. **åˆå§‹è®¾ç½®**
   ```bash
   ./llmservingsim setup-perf      # ç”Ÿæˆæ€§èƒ½æ¨¡å‹
   ./llmservingsim extend-models   # æ·»åŠ æ¨¡å‹æ”¯æŒ
   ```

2. **å¯åŠ¨æœåŠ¡**
   ```bash
   ./llmservingsim server --model "qwen/Qwen3-8B" --hardware A100
   ```

3. **æµ‹è¯•éªŒè¯**
   ```bash
   ./llmservingsim test-api
   ```

## ğŸ“ æ·»åŠ æ–°å·¥å…·

å¦‚æœéœ€è¦æ·»åŠ æ–°çš„å·¥å…·è„šæœ¬ï¼š

1. **ç¡®å®šåˆ†ç±»**ï¼šscripts/, perf_models/, æˆ– tests/
2. **æ·»åŠ åˆ°å¯¹åº”ç›®å½•**
3. **æ›´æ–° `llmservingsim` ä¸»è„šæœ¬**
4. **æ›´æ–°æ­¤READMEæ–‡æ¡£**

## ğŸ› ï¸ ç»´æŠ¤è¯´æ˜

- æ‰€æœ‰è„šæœ¬éƒ½åº”è¯¥æ˜¯å¯æ‰§è¡Œçš„ (`chmod +x`)
- Pythonè„šæœ¬åº”è¯¥æœ‰ `#!/usr/bin/env python3` shebang
- Shellè„šæœ¬åº”è¯¥æœ‰ `#!/bin/bash` shebang
- æ‰€æœ‰å·¥å…·éƒ½åº”è¯¥æœ‰å¸®åŠ©ä¿¡æ¯ (`--help`)
